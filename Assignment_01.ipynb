{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4FA3UxIR6xk"
      },
      "source": [
        "Neural Network Class Implementation in Numpy Library\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sigmoid function definition\n",
        "\n",
        "def sig_ftn(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ],
      "metadata": {
        "id": "uAXyHtbuK17-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#derivative of sigmoid function\n",
        "\n",
        "def sig_derivative(x):\n",
        "    return sig_ftn(x) * (1 - sig_ftn(x))"
      ],
      "metadata": {
        "id": "1P9mZ2SxK12c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feedforward function\n",
        "\n",
        "def feedforward(self, x):\n",
        "  \n",
        "        a = np.copy(x)\n",
        "        self.z_s = []\n",
        "        self.a_s = [a]\n",
        "        for i in range(len(self.weights)):\n",
        "            z_i = np.dot(self.weights[i],a) + self.biases[i]\n",
        "            self.z_s.append(z_i)\n",
        "            a = sig_ftn(self.z_s[-1])\n",
        "            self.a_s.append(a)\n",
        "        return a"
      ],
      "metadata": {
        "id": "Q4SM1p9xK1wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining stochastic gradient descent\n",
        "\n",
        "def SGD(self,train_data,lr,mini_batch_size,epochs,test_data = None):\n",
        "        train_data = list(train_data)\n",
        "        test_data = list(test_data)\n",
        "        if test_data :\n",
        "            n = len(train_data)\n",
        "            n_test = len(test_data)\n",
        "            for i in range(epochs):\n",
        "                random.shuffle(train_data)\n",
        "                mini_batches = [\n",
        "                    train_data[j:j+mini_batch_size]\n",
        "                    for j in range(0,n,mini_batch_size)]\n",
        "                for mini_batch in mini_batches:\n",
        "                    self.update_ftn(mini_batch,lr)\n",
        "                if test_data:\n",
        "                   print (\"Epoch {0}: {1} / {2}\".format(i, self.evaluate_ftn(test_data), n_test))\n",
        "                else:\n",
        "                   print (\"Epoch {0} complete\".format(i))"
      ],
      "metadata": {
        "id": "8qyQ17cIK1q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to update weights\n",
        "\n",
        "def update_ftn(self, mini_batch, lr):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "        self.weights = [w-(lr/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(lr/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)]"
      ],
      "metadata": {
        "id": "wVqoinH2K1lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backpropagation function\n",
        "\n",
        "def backprop(self, x, y):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        self.feedforward(x)\n",
        "        \n",
        "        delta = ((y-self.a_s[-1])*(sig_derivative(self.z_s[-1])))\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = delta.dot(self.a_s[-2].T)\n",
        "        for l in range(2, self.no_layers):\n",
        "            z = self.z_s[-l]\n",
        "            d_sig = sig_derivative(z)\n",
        "            delta = (self.weights[-l+1].T.dot(delta))*d_sig\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = delta.dot(self.a_s[-l-1].T)\n",
        "        return (nabla_b, nabla_w)"
      ],
      "metadata": {
        "id": "HG0_6aMjK1fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation function\n",
        "\n",
        "def evaluate_ftn(self, test_data):\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        \n",
        "        return  sum(int(x == y) for (x, y) in test_results)"
      ],
      "metadata": {
        "id": "61eVZHIhK1Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qb-bW3ChK09F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNI6Si2BXpL"
      },
      "source": [
        "#Model Construction\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def sig_ftn(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def sig_derivative(x):\n",
        "    return sig_ftn(x) * (1 - sig_ftn(x))\n",
        "\n",
        "class neural_network:                             \n",
        "    def __init__(self,num_neurons):\n",
        "      self.no_layers = len(num_neurons)\n",
        "      self.num_neurons = num_neurons\n",
        "      self.weights =[]\n",
        "      self.biases = []\n",
        "      for i in range(len(num_neurons)-1):\n",
        "            \n",
        "            \n",
        "            self.weights.append(np.random.randn(num_neurons[i+1], num_neurons[i]))\n",
        "            self.biases.append(np.random.randn(num_neurons[i+1], 1))\n",
        "            \n",
        "    def feedforward(self, x):\n",
        "  \n",
        "        a = np.copy(x)\n",
        "        self.z_s = []\n",
        "        self.a_s = [a]\n",
        "        for i in range(len(self.weights)):\n",
        "            z_i = np.dot(self.weights[i],a) + self.biases[i]\n",
        "            self.z_s.append(z_i)\n",
        "            a = sig_ftn(self.z_s[-1])\n",
        "            self.a_s.append(a)\n",
        "        return a\n",
        "\n",
        "    def SGD(self,train_data,lr,mini_batch_size,epochs,test_data = None):\n",
        "        train_data = list(train_data)\n",
        "        test_data = list(test_data)\n",
        "        if test_data :\n",
        "            n = len(train_data)\n",
        "            n_test = len(test_data)\n",
        "            for i in range(epochs):\n",
        "                random.shuffle(train_data)\n",
        "                mini_batches = [\n",
        "                    train_data[j:j+mini_batch_size]\n",
        "                    for j in range(0,n,mini_batch_size)]\n",
        "                for mini_batch in mini_batches:\n",
        "                    self.update_ftn(mini_batch,lr)\n",
        "                if test_data:\n",
        "                   print (\"Epoch {0}: {1} / {2}\".format(i, self.evaluate_ftn(test_data), n_test))\n",
        "                else:\n",
        "                   print (\"Epoch {0} complete\".format(i))\n",
        "\n",
        "    def update_ftn(self, mini_batch, lr):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "        self.weights = [w-(lr/len(mini_batch))*nw\n",
        "                        for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b-(lr/len(mini_batch))*nb\n",
        "                       for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    \n",
        "    def backprop(self, x, y):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        self.feedforward(x)\n",
        "        \n",
        "        delta = ((y-self.a_s[-1])*(sig_derivative(self.z_s[-1])))\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = delta.dot(self.a_s[-2].T)\n",
        "        for l in range(2, self.no_layers):\n",
        "            z = self.z_s[-l]\n",
        "            d_sig = sig_derivative(z)\n",
        "            delta = (self.weights[-l+1].T.dot(delta))*d_sig\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = delta.dot(self.a_s[-l-1].T)\n",
        "        return (nabla_b, nabla_w)\n",
        "    \n",
        "\n",
        "    def evaluate_ftn(self, test_data):\n",
        "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
        "                        for (x, y) in test_data]\n",
        "        \n",
        "        return  sum(int(x == y) for (x, y) in test_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsU7t9rxJEiI",
        "outputId": "58649b56-da38-4630-98ff-25b4a91d0aaa"
      },
      "source": [
        "#Data Uploading\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EOtO5ZSJRDA"
      },
      "source": [
        "#to vectorize the data\n",
        "\n",
        "def vectorization_result(i):\n",
        "    x = np.zeros((10, 1))\n",
        "    x[i] = 1.0\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCDmh0WcJrx_",
        "outputId": "f6e7d6ee-24f9-408b-a2a7-ebb5c3f44311"
      },
      "source": [
        "#Model 1 : Neurons = 15 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_1 = neural_network([784, 15, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_1.SGD(training_data, 0.1, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 863 / 10000\n",
            "Epoch 1: 864 / 10000\n",
            "Epoch 2: 919 / 10000\n",
            "Epoch 3: 937 / 10000\n",
            "Epoch 4: 941 / 10000\n",
            "Epoch 5: 948 / 10000\n",
            "Epoch 6: 936 / 10000\n",
            "Epoch 7: 940 / 10000\n",
            "Epoch 8: 955 / 10000\n",
            "Epoch 9: 956 / 10000\n",
            "Epoch 10: 963 / 10000\n",
            "Epoch 11: 971 / 10000\n",
            "Epoch 12: 970 / 10000\n",
            "Epoch 13: 972 / 10000\n",
            "Epoch 14: 973 / 10000\n",
            "Epoch 15: 985 / 10000\n",
            "Epoch 16: 989 / 10000\n",
            "Epoch 17: 994 / 10000\n",
            "Epoch 18: 988 / 10000\n",
            "Epoch 19: 993 / 10000\n",
            "Epoch 20: 997 / 10000\n",
            "Epoch 21: 1004 / 10000\n",
            "Epoch 22: 1005 / 10000\n",
            "Epoch 23: 1001 / 10000\n",
            "Epoch 24: 1004 / 10000\n",
            "Epoch 25: 1008 / 10000\n",
            "Epoch 26: 1015 / 10000\n",
            "Epoch 27: 1017 / 10000\n",
            "Epoch 28: 1021 / 10000\n",
            "Epoch 29: 1024 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJotQZ45K7S8",
        "outputId": "0fc5925e-b01b-4503-ebe8-4426b1e0859f"
      },
      "source": [
        "#Model 2 : Neurons = 30 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_2 = neural_network([784, 30, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_2.SGD(training_data, 0.1, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 664 / 10000\n",
            "Epoch 1: 671 / 10000\n",
            "Epoch 2: 670 / 10000\n",
            "Epoch 3: 670 / 10000\n",
            "Epoch 4: 658 / 10000\n",
            "Epoch 5: 662 / 10000\n",
            "Epoch 6: 645 / 10000\n",
            "Epoch 7: 603 / 10000\n",
            "Epoch 8: 611 / 10000\n",
            "Epoch 9: 607 / 10000\n",
            "Epoch 10: 606 / 10000\n",
            "Epoch 11: 610 / 10000\n",
            "Epoch 12: 607 / 10000\n",
            "Epoch 13: 598 / 10000\n",
            "Epoch 14: 597 / 10000\n",
            "Epoch 15: 597 / 10000\n",
            "Epoch 16: 593 / 10000\n",
            "Epoch 17: 593 / 10000\n",
            "Epoch 18: 592 / 10000\n",
            "Epoch 19: 589 / 10000\n",
            "Epoch 20: 589 / 10000\n",
            "Epoch 21: 580 / 10000\n",
            "Epoch 22: 584 / 10000\n",
            "Epoch 23: 584 / 10000\n",
            "Epoch 24: 585 / 10000\n",
            "Epoch 25: 583 / 10000\n",
            "Epoch 26: 589 / 10000\n",
            "Epoch 27: 593 / 10000\n",
            "Epoch 28: 596 / 10000\n",
            "Epoch 29: 595 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5IHfS0jLIbv",
        "outputId": "48220d38-5c59-4a89-fe12-a342b93ec0fb"
      },
      "source": [
        "#Model 3 : Neurons = 100 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_3 = neural_network([784, 100, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_3.SGD(training_data, 0.1, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 657 / 10000\n",
            "Epoch 1: 675 / 10000\n",
            "Epoch 2: 663 / 10000\n",
            "Epoch 3: 660 / 10000\n",
            "Epoch 4: 657 / 10000\n",
            "Epoch 5: 656 / 10000\n",
            "Epoch 6: 649 / 10000\n",
            "Epoch 7: 643 / 10000\n",
            "Epoch 8: 641 / 10000\n",
            "Epoch 9: 635 / 10000\n",
            "Epoch 10: 641 / 10000\n",
            "Epoch 11: 636 / 10000\n",
            "Epoch 12: 640 / 10000\n",
            "Epoch 13: 639 / 10000\n",
            "Epoch 14: 642 / 10000\n",
            "Epoch 15: 643 / 10000\n",
            "Epoch 16: 646 / 10000\n",
            "Epoch 17: 647 / 10000\n",
            "Epoch 18: 656 / 10000\n",
            "Epoch 19: 659 / 10000\n",
            "Epoch 20: 669 / 10000\n",
            "Epoch 21: 655 / 10000\n",
            "Epoch 22: 642 / 10000\n",
            "Epoch 23: 646 / 10000\n",
            "Epoch 24: 615 / 10000\n",
            "Epoch 25: 618 / 10000\n",
            "Epoch 26: 667 / 10000\n",
            "Epoch 27: 726 / 10000\n",
            "Epoch 28: 743 / 10000\n",
            "Epoch 29: 739 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYZATVdlLUq6",
        "outputId": "53ef19d7-4a25-40d9-c81d-aa8822510ada"
      },
      "source": [
        "#Model 4 : Neurons = 15 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_4 = neural_network([784, 15, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_4.SGD(training_data, 3, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 840 / 10000\n",
            "Epoch 1: 829 / 10000\n",
            "Epoch 2: 567 / 10000\n",
            "Epoch 3: 561 / 10000\n",
            "Epoch 4: 562 / 10000\n",
            "Epoch 5: 573 / 10000\n",
            "Epoch 6: 578 / 10000\n",
            "Epoch 7: 572 / 10000\n",
            "Epoch 8: 578 / 10000\n",
            "Epoch 9: 582 / 10000\n",
            "Epoch 10: 557 / 10000\n",
            "Epoch 11: 544 / 10000\n",
            "Epoch 12: 545 / 10000\n",
            "Epoch 13: 524 / 10000\n",
            "Epoch 14: 524 / 10000\n",
            "Epoch 15: 530 / 10000\n",
            "Epoch 16: 528 / 10000\n",
            "Epoch 17: 529 / 10000\n",
            "Epoch 18: 528 / 10000\n",
            "Epoch 19: 530 / 10000\n",
            "Epoch 20: 530 / 10000\n",
            "Epoch 21: 534 / 10000\n",
            "Epoch 22: 533 / 10000\n",
            "Epoch 23: 532 / 10000\n",
            "Epoch 24: 531 / 10000\n",
            "Epoch 25: 535 / 10000\n",
            "Epoch 26: 537 / 10000\n",
            "Epoch 27: 537 / 10000\n",
            "Epoch 28: 533 / 10000\n",
            "Epoch 29: 534 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr8EJ7RmLfHi",
        "outputId": "40624ab3-80d5-4843-e350-06714b0e6dbc"
      },
      "source": [
        "#Model 5 : Neurons = 30 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_5 = neural_network([784, 30, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_5.SGD(training_data, 3, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 721 / 10000\n",
            "Epoch 1: 708 / 10000\n",
            "Epoch 2: 724 / 10000\n",
            "Epoch 3: 725 / 10000\n",
            "Epoch 4: 729 / 10000\n",
            "Epoch 5: 731 / 10000\n",
            "Epoch 6: 731 / 10000\n",
            "Epoch 7: 732 / 10000\n",
            "Epoch 8: 721 / 10000\n",
            "Epoch 9: 724 / 10000\n",
            "Epoch 10: 725 / 10000\n",
            "Epoch 11: 729 / 10000\n",
            "Epoch 12: 736 / 10000\n",
            "Epoch 13: 738 / 10000\n",
            "Epoch 14: 737 / 10000\n",
            "Epoch 15: 737 / 10000\n",
            "Epoch 16: 734 / 10000\n",
            "Epoch 17: 741 / 10000\n",
            "Epoch 18: 739 / 10000\n",
            "Epoch 19: 739 / 10000\n",
            "Epoch 20: 736 / 10000\n",
            "Epoch 21: 739 / 10000\n",
            "Epoch 22: 736 / 10000\n",
            "Epoch 23: 736 / 10000\n",
            "Epoch 24: 736 / 10000\n",
            "Epoch 25: 737 / 10000\n",
            "Epoch 26: 739 / 10000\n",
            "Epoch 27: 737 / 10000\n",
            "Epoch 28: 739 / 10000\n",
            "Epoch 29: 739 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyH0ZKuwLuLr",
        "outputId": "6a85ca9c-9bfd-4f69-845b-5cd9d0f08482"
      },
      "source": [
        "#Model 6 : Neurons = 100 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "nn_6 = neural_network([784, 100, 10])\n",
        "\n",
        "training_inputs = [np.reshape(x, (784, 1)) for x in x_train.copy()]\n",
        "training_results = [vectorization_result(y) for y in y_train.copy()]\n",
        "training_data = zip(training_inputs, training_results)\n",
        "\n",
        "test_inputs = [np.reshape(x, (784, 1)) for x in x_test.copy()]\n",
        "test_data = zip(test_inputs, y_test.copy())\n",
        "\n",
        "nn_6.SGD(training_data, 3, 16, 30, test_data=test_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 888 / 10000\n",
            "Epoch 1: 854 / 10000\n",
            "Epoch 2: 864 / 10000\n",
            "Epoch 3: 873 / 10000\n",
            "Epoch 4: 878 / 10000\n",
            "Epoch 5: 884 / 10000\n",
            "Epoch 6: 881 / 10000\n",
            "Epoch 7: 884 / 10000\n",
            "Epoch 8: 886 / 10000\n",
            "Epoch 9: 887 / 10000\n",
            "Epoch 10: 887 / 10000\n",
            "Epoch 11: 886 / 10000\n",
            "Epoch 12: 887 / 10000\n",
            "Epoch 13: 887 / 10000\n",
            "Epoch 14: 890 / 10000\n",
            "Epoch 15: 890 / 10000\n",
            "Epoch 16: 892 / 10000\n",
            "Epoch 17: 892 / 10000\n",
            "Epoch 18: 891 / 10000\n",
            "Epoch 19: 893 / 10000\n",
            "Epoch 20: 895 / 10000\n",
            "Epoch 21: 897 / 10000\n",
            "Epoch 22: 896 / 10000\n",
            "Epoch 23: 898 / 10000\n",
            "Epoch 24: 899 / 10000\n",
            "Epoch 25: 901 / 10000\n",
            "Epoch 26: 900 / 10000\n",
            "Epoch 27: 901 / 10000\n",
            "Epoch 28: 901 / 10000\n",
            "Epoch 29: 901 / 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgTsp4vSSPEw"
      },
      "source": [
        "Neural Network Implementation in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-IT1jnVSeyG"
      },
      "source": [
        "#Data Import \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, l_train), (x_test, l_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ3vFTNfWD_d"
      },
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "import numpy as np\n",
        "(x_train, l_train), (x_test, l_test) = mnist.load_data()\n",
        "y_train = np.zeros((l_train.shape[0], l_train.max()+1), dtype=np.float32)\n",
        "y_train[np.arange(l_train.shape[0]), l_train] = 1\n",
        "y_test = np.zeros((l_test.shape[0], l_test.max()+1), dtype=np.float32)\n",
        "y_test[np.arange(l_test.shape[0]), l_test] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1TYsCdiWM3R",
        "outputId": "f7be8b43-7ac0-42f9-92ed-8ebe2625d06a"
      },
      "source": [
        "#Model 1 : Neurons = 15 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_1 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(15,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_1.compile(optimizer = tf.keras.optimizers.SGD(0.1),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_1.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_1.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0708 - accuracy: 0.4755\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0384 - accuracy: 0.7778\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0313 - accuracy: 0.8161\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0264 - accuracy: 0.8368\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0256 - accuracy: 0.8396\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0251 - accuracy: 0.8452\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0235 - accuracy: 0.8523\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0220 - accuracy: 0.8587\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0223 - accuracy: 0.8562\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0214 - accuracy: 0.8610\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0217 - accuracy: 0.8595\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0205 - accuracy: 0.8682\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0211 - accuracy: 0.8623\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0213 - accuracy: 0.8601\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0209 - accuracy: 0.8628\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0201 - accuracy: 0.8672\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0199 - accuracy: 0.8705\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0196 - accuracy: 0.8729\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0196 - accuracy: 0.8711\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0202 - accuracy: 0.8669\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0190 - accuracy: 0.8763\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0189 - accuracy: 0.8767\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0189 - accuracy: 0.8761\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0189 - accuracy: 0.8734\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0196 - accuracy: 0.8698\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0186 - accuracy: 0.8794\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0179 - accuracy: 0.8817\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0181 - accuracy: 0.8809\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0190 - accuracy: 0.8759\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0188 - accuracy: 0.8763\n",
            "313/313 [==============================] - 0s 963us/step - loss: 0.0180 - accuracy: 0.8827\n",
            "test_accuracy: 0.8827000260353088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNYn_9D1WWUW",
        "outputId": "adc13f2c-1172-47f6-b90a-c3263660fe1c"
      },
      "source": [
        "#Model 2 : Neurons = 30 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_2 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(30,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_2.compile(optimizer = tf.keras.optimizers.SGD(0.1),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_2.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_2.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0625 - accuracy: 0.5646\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0269 - accuracy: 0.8507\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0215 - accuracy: 0.8736\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0201 - accuracy: 0.8793\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0191 - accuracy: 0.8836\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0178 - accuracy: 0.8883\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0168 - accuracy: 0.8929\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0172 - accuracy: 0.8912\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0161 - accuracy: 0.8965\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0162 - accuracy: 0.8962\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0166 - accuracy: 0.8940\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0158 - accuracy: 0.8983\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0157 - accuracy: 0.8988\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0146 - accuracy: 0.9058\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0154 - accuracy: 0.8988\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0155 - accuracy: 0.8979\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0154 - accuracy: 0.8998\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0153 - accuracy: 0.8998\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0147 - accuracy: 0.9032\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0158 - accuracy: 0.8983\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0156 - accuracy: 0.8992\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0143 - accuracy: 0.9059\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0145 - accuracy: 0.9068\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0140 - accuracy: 0.9099\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0142 - accuracy: 0.9079\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0134 - accuracy: 0.9116\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0134 - accuracy: 0.9123\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0135 - accuracy: 0.9123\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0129 - accuracy: 0.9152\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0135 - accuracy: 0.9122\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9078\n",
            "test_accuracy: 0.907800018787384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ts24Ub5WbYo",
        "outputId": "b6a81cbe-950e-4ab9-ea91-75d51320d1fa"
      },
      "source": [
        "#Model 3 : Neurons = 100 , Learning Rate = 0.1 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_3 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(100,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_3.compile(optimizer = tf.keras.optimizers.SGD(0.1),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_3.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_3.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0480 - accuracy: 0.6700\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0189 - accuracy: 0.8882\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0163 - accuracy: 0.8989\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0144 - accuracy: 0.9118\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0139 - accuracy: 0.9138\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0132 - accuracy: 0.9174\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0125 - accuracy: 0.9242\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0117 - accuracy: 0.9297\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0115 - accuracy: 0.9299\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0108 - accuracy: 0.9319\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0107 - accuracy: 0.9327\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0109 - accuracy: 0.9312\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0105 - accuracy: 0.9338\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0103 - accuracy: 0.9365\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0103 - accuracy: 0.9348\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0102 - accuracy: 0.9361\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0103 - accuracy: 0.9361\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0099 - accuracy: 0.9385\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0095 - accuracy: 0.9407\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0096 - accuracy: 0.9397\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0094 - accuracy: 0.9418\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0093 - accuracy: 0.9417\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0091 - accuracy: 0.9421\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0092 - accuracy: 0.9419\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0093 - accuracy: 0.9409\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0088 - accuracy: 0.9443\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0086 - accuracy: 0.9464\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0088 - accuracy: 0.9440\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0088 - accuracy: 0.9445\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0090 - accuracy: 0.9424\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9430\n",
            "test_accuracy: 0.9430000185966492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaKiPRKfWgZA",
        "outputId": "9903fd43-5826-493a-9baf-406b7ad27061"
      },
      "source": [
        "#Model 4 : Neurons = 15 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_4 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(15,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_4.compile(optimizer = tf.keras.optimizers.SGD(3),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_4.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_4.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0861 - accuracy: 0.1972\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0845 - accuracy: 0.2004\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0781 - accuracy: 0.3102\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0751 - accuracy: 0.3385\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0729 - accuracy: 0.3705\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0725 - accuracy: 0.3930\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0745 - accuracy: 0.3890\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0753 - accuracy: 0.3306\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0702 - accuracy: 0.4061\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0686 - accuracy: 0.4478\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0760 - accuracy: 0.3065\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0839 - accuracy: 0.1962\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0835 - accuracy: 0.1996\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0830 - accuracy: 0.2065\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0780 - accuracy: 0.2674\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0761 - accuracy: 0.3039\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0816 - accuracy: 0.2374\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0756 - accuracy: 0.3213\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0776 - accuracy: 0.2941\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0780 - accuracy: 0.2756\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0775 - accuracy: 0.3265\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0760 - accuracy: 0.3548\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0740 - accuracy: 0.3601\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0743 - accuracy: 0.3325\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0727 - accuracy: 0.3623\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0750 - accuracy: 0.3224\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0738 - accuracy: 0.3466\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0749 - accuracy: 0.3650\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0744 - accuracy: 0.3511\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0735 - accuracy: 0.3496\n",
            "313/313 [==============================] - 0s 969us/step - loss: 0.0730 - accuracy: 0.3641\n",
            "test_accuracy: 0.36410000920295715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJRHIH5IWlif",
        "outputId": "35aacf7d-9cab-40a8-ef77-d9d447730ee3"
      },
      "source": [
        "#Model 5 : Neurons = 30 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_5 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(30,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_5.compile(optimizer = tf.keras.optimizers.SGD(3),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_5.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_5.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0817 - accuracy: 0.2813\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0754 - accuracy: 0.3450\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0720 - accuracy: 0.3682\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0633 - accuracy: 0.4894\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0684 - accuracy: 0.4143\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0610 - accuracy: 0.5119\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0589 - accuracy: 0.5333\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0607 - accuracy: 0.5181\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0628 - accuracy: 0.4861\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0580 - accuracy: 0.5593\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0537 - accuracy: 0.5884\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0530 - accuracy: 0.5933\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0542 - accuracy: 0.5815\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0574 - accuracy: 0.5462\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0591 - accuracy: 0.5432\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0555 - accuracy: 0.5667\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0581 - accuracy: 0.5493\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0565 - accuracy: 0.5590\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0557 - accuracy: 0.5664\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0540 - accuracy: 0.5957\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0593 - accuracy: 0.5302\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0595 - accuracy: 0.5426\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0552 - accuracy: 0.5788\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0529 - accuracy: 0.5930\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0509 - accuracy: 0.6007\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0526 - accuracy: 0.6077\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0531 - accuracy: 0.6031\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0527 - accuracy: 0.5916\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0530 - accuracy: 0.5981\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0527 - accuracy: 0.6062\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.6585\n",
            "test_accuracy: 0.6585000157356262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZfVsuyvWrGt",
        "outputId": "1549e593-c741-4b62-bd30-94b87294d59c"
      },
      "source": [
        "#Model 6 : Neurons = 100 , Learning Rate = 3 , Batch Size =  16 , Epochs = 30\n",
        "\n",
        "model_6 = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(100,activation=tf.nn.sigmoid),\n",
        "                          keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model_6.compile(optimizer = tf.keras.optimizers.SGD(3),\n",
        "              loss = 'mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "model_6.fit(x_train,y_train,epochs=30,batch_size =16)\n",
        "test_loss , test_acc = model_6.evaluate(x_test,y_test)\n",
        "print('test_accuracy:',test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0686 - accuracy: 0.4378\n",
            "Epoch 2/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0591 - accuracy: 0.5343\n",
            "Epoch 3/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0654 - accuracy: 0.4748\n",
            "Epoch 4/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0611 - accuracy: 0.5285\n",
            "Epoch 5/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0628 - accuracy: 0.5108\n",
            "Epoch 6/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0650 - accuracy: 0.4889\n",
            "Epoch 7/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0613 - accuracy: 0.5244\n",
            "Epoch 8/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0633 - accuracy: 0.4783\n",
            "Epoch 9/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0609 - accuracy: 0.5144\n",
            "Epoch 10/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0588 - accuracy: 0.5371\n",
            "Epoch 11/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0694 - accuracy: 0.4528\n",
            "Epoch 12/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0691 - accuracy: 0.4578\n",
            "Epoch 13/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0719 - accuracy: 0.4039\n",
            "Epoch 14/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0698 - accuracy: 0.4291\n",
            "Epoch 15/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0663 - accuracy: 0.4637\n",
            "Epoch 16/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0637 - accuracy: 0.4714\n",
            "Epoch 17/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0611 - accuracy: 0.5241\n",
            "Epoch 18/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0549 - accuracy: 0.6020\n",
            "Epoch 19/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0571 - accuracy: 0.5510\n",
            "Epoch 20/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0553 - accuracy: 0.5936\n",
            "Epoch 21/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0596 - accuracy: 0.5474\n",
            "Epoch 22/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0598 - accuracy: 0.5216\n",
            "Epoch 23/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0622 - accuracy: 0.5133\n",
            "Epoch 24/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0582 - accuracy: 0.5635\n",
            "Epoch 25/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0544 - accuracy: 0.5960\n",
            "Epoch 26/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0554 - accuracy: 0.5799\n",
            "Epoch 27/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0604 - accuracy: 0.5216\n",
            "Epoch 28/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0614 - accuracy: 0.5012\n",
            "Epoch 29/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0578 - accuracy: 0.5498\n",
            "Epoch 30/30\n",
            "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0609 - accuracy: 0.5251\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0574 - accuracy: 0.5527\n",
            "test_accuracy: 0.5526999831199646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aEZiU3aciL7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}